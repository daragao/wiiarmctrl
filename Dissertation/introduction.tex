
	This is a introductory chapter, elaborating on the motivation and contribution in which this work is based on.

\section{Motivation}

 \acf{HRI} is a part of the \acf{HCI} field that is becoming more fundamental each day, with the progress in robotics, and the discovery of the specific problems that arise from the robotics area\cite{hri:springerlink:10.1007/s12369-010-0081-8}. The hope that robots might some day populate the world and help us with our daily tasks is a distant truth in most peoples minds, often because the simple functions that robots do nowadays are accompanied by complex interfaces, that discourage most users from its utilization. Demands for better and original interaction forms in the industry led to the appearance of a set of interesting interfaces that are still to be explored and can introduce novel ways of interaction with robots. The mixture between these two worlds, games and robotics, as resulted in an interesting approach for interaction with robots by people with low or no knowledge about robots.
 
 With a completely different goal than the \ac{HRI} objective, the gaming industry has released several interface devices that are sold worldwide at a low cost. Many of these gaming interfaces use state of the art technology and allow an easy computer connection. Because of this cheap access to typically expensive hardware, many researchers and hobbyists have hacked these devices so that software development is possible to meet their personal needs, along with this hacking communities were formed to support the work that was being done, and that still needs to be done. These commercially available products have increasingly become the main focus of many projects that explore new and unexpected interaction techniques. Most of the exploration evolution with this devices has been appearing both in journals and conferences, as well as on-line videos and wikis, and usually with very technical and direct explanations. Researchers are trying to keep up with the pace of hobbyists, who are not worried about the coherence and consistency of their work, and study how this devices can really be useful for their projects.

 Because of their characteristics many of these devices are very good to be used as Human-Robot interfaces, not so expensive as the alternatives, and already known and used by a large group of people, mostly gamers, but with very different characteristics. The amount of inspiration that can be taken out of the web, from works built by others has not only been a plus to the researchers but also to the manufactures of these products, which have considered this kind of use an advantage\footnote{\url{http://www.techflash.com/seattle/2010/11/microsoft-kinect-not-hacked-left.html}}. With these robust gaming devices, that are becoming more common, it is important to understand how to map the proper device to the proper interaction form. Humanoids have different needs from a mechanical arm, those needs should be taken into consideration when deciding which might be the best interaction device and form.

 The iCub is a humanoid social robot involved in projects that range from psychology to the grasping of objects. The interaction with the arms of the robot is typically made either through programming, or a specific software that allows to move each motor independently. This system although working, is neither simple or intuitive to reach a desired position, taking a lot of time to execute and plan, each time that there is any small change to be made. This difficulty becomes often an obstacle for small changes that might help in a execution of a task, but are left undone due to being too expensive. Creating a simpler interface that is usable can change this detail which can result in faster development cycles. Interfaces that are able to do motion capture can also be very helpful in programming by demonstration, where human gestures need to be captured so that an agent, in this case a humanoid, can learn from them.

 An improper interface to the function that the robot is supposed to be involved in might unable the success of that task. On the other hand a good interface during development helps to speed up the work, allowing the research to be abstracted from minor details. If a researcher needs to position an arm to be able to test a grasp, it is time consuming and useless to learn how to program a system that keeps positioning the arm to its proper position, just to make a grasp. A good interaction must be intuitive, natural, correspond to the user expectations and be specific. To achieve this, it is important not only the data that an interaction device may retrieve, but also how the robot that we are interacting with responds. That mapping is what might make a difference in solving a interaction objective of a user, a good mapping meets user expectations.
 
 The novel interaction devices available at low prices from the gaming manufactures, might serve as a good platform for \ac{HRI} work, although most of these devices are very unexplored, and need the very basics to be studied and annotated. The works that hobbyist and the hacking community created, that can be followed on-line, serve as good inspiration for the use of the novel devices, but it is important to better understand how do mapping these devices to specific robots having in mind the tasks that will be executed by the controlled robot will affect the users performance and success the execution of the pretended tasks.

\section{Contribution}

	This work studies the advantages and disadvantages of two novel gaming interfaces, a typical \acf{GUI} and \acf{DPad}, as an humanoid robot interface. It is hoped that the comparison between the several systems that have been increasingly used by researchers and developers becomes useful as a starting point for future works with interfaces and interaction. Also, it was noted that the modules developed during this work might also be useful utilities for the iCub and Yarp community. 
	
	The gaming interfaces used were the Wii gaming console remote (the \acf{Wiimote}), with the \acf{MP} sensor extension, and the Kinect camera for the Xbox 360, these are novel interfaces, that still do not have many studies about them available, much of the information available is on-line, through wikis and blogs. The Kinect was actually released during the development of this work, November 2010, and it was only reverse engineered to be used with a computer by the end of this work. However the interaction allowed by the Kinect camera is such a novelty that simple tests with it can already produce interesting results, and can adapt to robotics in a very clear and intuitive way.
	
	To understand the best and most interesting interaction devices, we developed several interaction modules, each module permitted to two have different interaction forms with the same device, a kinematic form and a motor form. So there were specific modules developed for the \ac{Wiimote} and for the Kinect, that took advantage of different interaction forms.
 
 The \ac{Wiimote} allowed us to create three distinct interaction forms: (1) the movements made by the user are interpreted by the iCub to move in a predefined manner, always following the user movement; (2) the direct control of the iCub motors, each type of rotation allows the user to control a different motor; (3) the cursor pad on the \ac{Wiimote} is used to control the iCub arm directionally. The third form is considered a typical interface because being used with the \ac{Wiimote} is no different from using it with any other device that has six buttons.
 
 The Kinect had two interaction forms: (1) the hand movement of a user would be interpreted by the iCub to move in a predefined manner, always following the user hand; (2) the motors would be controlled directly, mimicking the user pose. This interfaces are set on or off using the \ac{Wiimote}.
 
 To test these interaction methods, modules were created that can be used with other purposes, as some already have been. These programs were developed in an open-source way, having in mind that another developer might reuse parts of the program or data being collected by the program. It has also been made an effort in implementing some of these solutions as useful programs for the Vislab developers, to facilitate simple and repetitive tasks, such as positioning the parts of a robot in a proper way fo use. From the data that can be collected with these new modules, it is hoped that it might be put to use as learning data sets, for the robots comprehension of human tasks and movements.
 
 For the comparison users with different backgrounds were asked to perform several tasks with each one of this interaction modules. The results of the evaluation made can now be used as a starting point for other interaction works that might want to use this type of devices for humanoid control. During the tests there were annotations made relatively to the time that it took users to perform tasks, comments of the users, and difficulties that might have been sensed by the test orientator from the users. 
 
 Because of the modules high adaptability, this interaction programs were extended to the Vizzy robot, a social and mobile robot, as a form of demonstrating this robot capabilities. This robot is distinct from the iCub, although it also uses Yarp which made it a good recipient for part of the modules developed for the iCub.
 
 The modules developed explore the novel interaction devices that have been emerging from the gaming industry. The interaction devices used today for gaming are interesting, cheap, replacements of typically expensive hardware. Due to their high and easy availability they also result in a high production of interaction works. Although this is a very strong inspiration, it not always results in proper interactions for the target system, we hope that the results of this work can contribute to better the understanding of how to make this novel devices adapt to an humanoid.
 
\section{Outline}

	This document is organized in six chapters, and several chapter sections.
	
	Chapter \ref{chapter:Related Work}, is the related work chapter, it presents a brief literature review on the fields of \ac{HRI}, the \ac{Wiimote}, the Kinect sensor, the iCub robot, and iCub specific software as \ac{Yarp}.
	
	Chapter \ref{chapter:Proposed Interface System}, describes how the proposed interaction forms developed and used for the interfaces comparison work, and some of the options made.
	
	Chapter \ref{chapter:Applications}, presents the software implementation techniques and options used for the interaction software developed.
	
	Chapter \ref{chapter:Evaluation}, describes the test done with the users to understand the characteristics of the interaction devices, and its results.
	
	Chapter \ref{chapter:Conclusions}, is a concluding chapter, where a overall view of the work done and main conclusion drawn is made, as well as future work suggestions are made.
	
	With the exception of the first and last chapter, all the other chapters have a concluding remarks section, where a overview of the chapter is made.
	